{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Avinash-ml07/Smart-Surveillance-Artist-Real-time-Security-Feed-with-Threat-Detection-Artistic-Stylization/blob/main/Security_detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tb4KR7_WnENQ"
      },
      "outputs": [],
      "source": [
        "!pip install -q ultralytics\n",
        "!pip install -q tensorflow opencv-python matplotlib\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C1hmycNJnOVM"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "import requests\n",
        "\n",
        "url = \"https://ultralytics.com/images/bus.jpg\"\n",
        "image = Image.open(requests.get(url, stream=True).raw)\n",
        "image.save(\"sample.jpg\")\n",
        "image.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lwM3L53snaXQ"
      },
      "outputs": [],
      "source": [
        "from ultralytics import YOLO\n",
        "\n",
        "model = YOLO('yolov8n.pt')\n",
        "results = model('sample.jpg', save=True)\n",
        "\n",
        "results[0].show()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input, decode_predictions\n",
        "from tensorflow.keras.preprocessing import image\n",
        "import numpy as np\n",
        "\n",
        "img = image.load_img('sample.jpg', target_size=(224, 224))\n",
        "x = image.img_to_array(img)\n",
        "x = np.expand_dims(x, axis=0)\n",
        "x = preprocess_input(x)\n",
        "\n",
        "model = ResNet50(weights='imagenet')\n",
        "preds = model.predict(x)\n",
        "print(\"Top Predictions:\", decode_predictions(preds, top=3)[0])\n",
        "\n",
        "print(\"\\nüß± Scene Classification by ResNet:\")\n",
        "for label in scene_preds:\n",
        "    print(f\"- {label[1]} ({round(label[2]*100, 2)}%)\")\n"
      ],
      "metadata": {
        "id": "Caa9W2TypP_R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Objects Detected:\", detected_labels)\n",
        "print(\"Scene Classification:\", scene_preds[0][1])\n"
      ],
      "metadata": {
        "id": "KihQzWGlfIiv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import os\n",
        "\n",
        "content_path = \"/content/input.jpg\"\n",
        "style_path = \"/content/image.jpeg\"\n",
        "\n",
        "if os.path.exists(content_path) and os.path.exists(style_path):\n",
        "    print(\"‚úÖ Both images found\")\n",
        "else:\n",
        "    print(\"‚ùå Missing image files\")\n"
      ],
      "metadata": {
        "id": "FT07nE9whgOz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "def load_img(path_to_img):\n",
        "    max_dim = 512\n",
        "    img = tf.io.read_file(path_to_img)\n",
        "    img = tf.image.decode_jpeg(img, channels=3)  # üëà Force JPEG decoding\n",
        "    img = tf.image.convert_image_dtype(img, tf.float32)\n",
        "    shape = tf.cast(tf.shape(img)[:-1], tf.float32)\n",
        "    scale = max_dim / max(shape)\n",
        "    new_shape = tf.cast(shape * scale, tf.int32)\n",
        "    img = tf.image.resize(img, new_shape)\n",
        "    img = img[tf.newaxis, :]\n",
        "    return img\n",
        "\n",
        "content_image = load_img(content_path)\n",
        "style_image = load_img(style_path)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "g8csDZgLfQmm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.subplot(1, 2, 1)\n",
        "plt.title(\"Content\")\n",
        "plt.imshow(tf.squeeze(content_image))\n",
        "plt.axis('off')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.title(\"Style\")\n",
        "plt.imshow(tf.squeeze(style_image))\n",
        "plt.axis('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "gYAjMPlqf8s4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow_hub as hub\n",
        "\n",
        "hub_model = hub.load('https://tfhub.dev/google/magenta/arbitrary-image-stylization-v1-256/2')\n",
        "\n",
        "stylized_image = hub_model(tf.constant(content_image), tf.constant(style_image))[0]\n",
        "\n",
        "plt.figure(figsize=(6, 6))\n",
        "plt.imshow(tf.squeeze(stylized_image))\n",
        "plt.title(\"Stylized Output\")\n",
        "plt.axis('off')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "3SzEP4CRgP7P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "threat_objects = {\"knife\", \"gun\", \"firearm\", \"weapon\"}\n",
        "found_threat = any(obj in detected_labels for obj in threat_objects)\n",
        "\n",
        "if  found_threat:\n",
        "    print(\"üö® Threat detected! stylization.\")\n",
        "    stylized_image = hub_model(tf.constant(content_image), tf.constant(style_image))[0]\n",
        "    plt.imshow(tf.squeeze(stylized_image))\n",
        "    plt.title(\"Stylized Output\")\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "else:\n",
        "    print(\"üö® No Threat detected! Skipping stylization.\")\n",
        "    plt.imshow(tf.squeeze(content_image))\n",
        "    plt.title(\"Stylized Output\")\n",
        "    plt.axis('off')\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "Yn5Rs_cSgfJs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/ultralytics/yolov5.git\n",
        "%cd yolov5\n",
        "!pip install -r requirements.txt\n"
      ],
      "metadata": {
        "id": "80IqAAe3grGW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from IPython.display import display, Image\n",
        "from PIL import Image as PILImage\n",
        "import cv2\n",
        "import numpy as np\n"
      ],
      "metadata": {
        "id": "zPn4mKtCqwT_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = torch.hub.load('ultralytics/yolov5', 'yolov5s', pretrained=True)\n"
      ],
      "metadata": {
        "id": "x3ac_2wgqzvA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img = PILImage.open(\"input.jpg\")\n",
        "\n",
        "results = model(img)\n",
        "\n",
        "results.print()\n",
        "results.show()\n"
      ],
      "metadata": {
        "id": "FhGQ_Sc5q14g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import cv2\n",
        "\n",
        "model = torch.hub.load('ultralytics/yolov5', 'yolov5s', pretrained=True)\n",
        "cap = cv2.VideoCapture(0)\n",
        "while True:\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "        break\n",
        "\n",
        "    results = model(frame)\n",
        "    cv2.imshow('YOLO Detection', np.squeeze(results.render()))\n",
        "\n",
        "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "        break\n",
        "\n",
        "cap.release()\n",
        "cv2.destroyAllWindows()\n"
      ],
      "metadata": {
        "id": "w0_wQLMDrALl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "abnormal_classes = ['knife', 'person', 'fire']\n",
        "\n",
        "for *box, conf, cls in results.xyxy[0]:\n",
        "    label = model.names[int(cls)]\n",
        "    if label in abnormal_classes:\n",
        "        print(f\"‚ö†Ô∏è Abnormal object detected: {label}\")\n"
      ],
      "metadata": {
        "id": "uzfCLUDXrXyF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5iffSng0rb8x"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMZsJY1UknfC0UTPVM1zVK2",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}